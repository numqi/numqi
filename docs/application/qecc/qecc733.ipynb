{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QECC-733\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/numqi/numqi/blob/main/docs/application/qecc/qecc733.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "Whether quantum error-correction code (QECC) `((7,3,3))` exists or not is an open question. This notebook is to explore the possibility of QECC-733."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import numqi\n",
    "except ImportError:\n",
    "    %pip install numqi\n",
    "    import numqi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VarQECSchmidt(torch.nn.Module):\n",
    "    def __init__(self, num_qubit, num_logical_dim, error_op_full):\n",
    "        super().__init__()\n",
    "        self.num_logical_dim = num_logical_dim\n",
    "        self.num_qubit = num_qubit\n",
    "        self.error_op_torch = torch.tensor(np.stack(error_op_full, axis=0).reshape(-1,2**num_qubit)).to_sparse_csr()\n",
    "        np_rng = np.random.default_rng()\n",
    "        tmp0 = np_rng.normal(size=(2,num_logical_dim,2**num_qubit))\n",
    "        self.theta = torch.nn.Parameter(torch.tensor(tmp0, dtype=torch.float64))\n",
    "        self.q0_torch = None\n",
    "        self.mask = torch.triu(torch.ones(num_logical_dim, num_logical_dim, dtype=torch.complex128), diagonal=1)\n",
    "\n",
    "    def forward(self):\n",
    "        q0 = torch.complex(self.theta[0], self.theta[1])\n",
    "        q0_orth = []\n",
    "        for ind0 in range(q0.shape[0]):\n",
    "            tmp0 = q0[ind0]\n",
    "            for x in q0_orth:\n",
    "                tmp0 = tmp0 - torch.vdot(x,tmp0)*x\n",
    "            q0_orth.append(tmp0 / torch.linalg.norm(tmp0))\n",
    "        q0 = torch.stack(q0_orth, dim=1)\n",
    "        inner_product = q0.T.conj() @ (self.error_op_torch @ q0).reshape(-1, *q0.shape)\n",
    "        self.q0_torch = q0.detach().T\n",
    "        tmp0 = (inner_product*self.mask).reshape(-1)\n",
    "        tmp1 = torch.diagonal(inner_product, dim1=1, dim2=2).real\n",
    "        tmp2 = (tmp1 - tmp1.mean(axis=1, keepdims=True)).reshape(-1)\n",
    "        loss = torch.vdot(tmp0, tmp0).real + torch.dot(tmp2, tmp2)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubit = 7\n",
    "num_logical_dim = 3\n",
    "distance = 3\n",
    "error_op_full = numqi.qec.make_error_list(num_qubit, distance, tag_full=True)\n",
    "model = VarQECSchmidt(num_qubit, num_logical_dim, error_op_full)\n",
    "kwargs = dict(theta0=('uniform',-1,1), tol=1e-7, print_freq=0, early_stop_threshold=0.01)\n",
    "theta_optim = numqi.optimize.minimize(model, num_repeat=2, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can minimize the loss function to almost `0`, then you have found a QECC-733."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
