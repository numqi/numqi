{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test function list\n",
    "\n",
    "In this part, we will show gradient descent optimization on various 2-dimensioanl test function from this wiki page [wiki/test-function-for-optimization](https://en.wikipedia.org/wiki/Test_functions_for_optimization).\n",
    "\n",
    "We will plot the function landscape around the optimal point and also the optimization path.\n",
    "\n",
    "We choose the initial point for optimization uniformly from the range $[-1, 1]$, so it could be biased to the local optimal point around the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import numqi\n",
    "\n",
    "np_rng = np.random.default_rng()\n",
    "hf_uniform_para = lambda *x: torch.nn.Parameter(torch.tensor(np_rng.uniform(-1, 1, size=x), dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hf_demo(model, num_repeat=3, xlim=None, ylim=None, x_optim=None, tag_logscale=False):\n",
    "    theta_optim,info = numqi.optimize.minimize(model, tol=1e-10, num_repeat=num_repeat, tag_record_path=True)\n",
    "    path = np.stack(info['path'])\n",
    "    print(f'optimal theta: {theta_optim.x}')\n",
    "    print(f'optimal loss: {theta_optim.fun}')\n",
    "\n",
    "    hf_model = numqi.optimize.hf_model_wrapper(model)\n",
    "    xdata = np.linspace(*xlim, 100)\n",
    "    ydata = np.linspace(*ylim, 100)\n",
    "    if len(x_optim)==2:\n",
    "        zdata = np.array([[hf_model(np.array([x, y]), tag_grad=False) for x in xdata] for y in ydata])\n",
    "    else:\n",
    "        zdata = np.array([[hf_model(np.concatenate([np.array([x, y]),x_optim[2:]]), tag_grad=False) for x in xdata] for y in ydata])\n",
    "    if tag_logscale:\n",
    "        zdata = np.log(np.maximum(1e-4,zdata))\n",
    "    fig,ax = plt.subplots()\n",
    "    contour_set = ax.contourf(xdata, ydata, zdata, levels=15, cmap='winter')\n",
    "    fig.colorbar(contour_set)\n",
    "    ax.plot([x_optim[0]], [x_optim[1]], 'rx', label='optimal')\n",
    "    ax.plot(path[:,0], path[:,1], '-', color='orange', label='path')\n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    if tag_logscale:\n",
    "        ax.set_title('log scale plot of loss function')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rastrigin function\n",
    "\n",
    "$$ f(x)=An+\\sum_{i=1}^n [x_i^2-A\\cos(2\\pi x_i)], A=10$$\n",
    "\n",
    "$$ f(0,\\cdots,0)=0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rastrigin(torch.nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.x = hf_uniform_para(n)\n",
    "        self.A = 10\n",
    "        # solution [0,0,...,0], 0\n",
    "\n",
    "    def forward(self):\n",
    "        x = self.x\n",
    "        loss = self.A*x.shape[0] + (x*x - self.A*torch.cos(2*np.pi*x)).sum()\n",
    "        return loss\n",
    "    \n",
    "n = 2\n",
    "model = Rastrigin(n)\n",
    "x_optim = np.zeros(n)\n",
    "hf_demo(model, num_repeat=10, xlim=(-5.12, 5.12), ylim=(-5.12, 5.12), x_optim=x_optim)\n",
    "# when n is large, it's almost impossible to find the global minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ackley function\n",
    "\n",
    "$$ f(x,y)=-20\\mathrm{exp}[-0.2\\sqrt{0.5(x^2+y^2)}] - \\mathrm{exp}[0.5(\\cos(2\\pi x)+\\cos(2\\pi y))] + e + 20 $$\n",
    "\n",
    "$$ f(0,0)=0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ackley(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # solution [0,0] 0\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        tmp0 = -20*torch.exp(-0.2*torch.sqrt(0.5*(x*x + y*y)))\n",
    "        tmp1 = -torch.exp(0.5*(torch.cos(2*np.pi*x)+torch.cos(2*np.pi*y))) + np.e + 20\n",
    "        ret = tmp0 + tmp1\n",
    "        return ret\n",
    "\n",
    "model = Ackley()\n",
    "x_optim = np.zeros(2)\n",
    "hf_demo(model, num_repeat=10, xlim=(-5, 5), ylim=(-5, 5), x_optim=x_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rosenbrock function\n",
    "\n",
    "$$ f(x)=\\sum_{i=1}^{n-1}[100(x_{i+1}-x_i^2)^2 + (1-x_i)^2] $$\n",
    "\n",
    "$$ f(1,\\cdots,1)=0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rosenbrock(torch.nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(n)\n",
    "        # solution [1,1,...,1] 0\n",
    "\n",
    "    def forward(self):\n",
    "        tmp0 = self.theta[1:] - self.theta[:-1]**2\n",
    "        tmp1 = 1-self.theta[:-1]\n",
    "        ret = 100*torch.dot(tmp0, tmp0) + torch.dot(tmp1,tmp1)\n",
    "        return ret\n",
    "    \n",
    "n = 2\n",
    "model = Rosenbrock(n)\n",
    "x_optim = np.ones(n)\n",
    "hf_demo(model, num_repeat=10, xlim=(-2, 2), ylim=(-1, 3), x_optim=x_optim, tag_logscale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beale function\n",
    "\n",
    "$$ f(x,y)=(1.5-x+xy)^2 + (2.25-x+xy^2)^2 + (2.625-x+xy^3)^2 $$\n",
    "\n",
    "$$ f(3,0.5)=0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Beale(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [3,0.5] 0\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        ret = (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x + x*y**3)**2\n",
    "        return ret\n",
    "\n",
    "model = Beale()\n",
    "x_optim = np.array([3, 0.5])\n",
    "hf_demo(model, num_repeat=10, xlim=(-4.5, 4.5), ylim=(-4.5, 4.5), x_optim=x_optim, tag_logscale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goldstein-Price function\n",
    "\n",
    "$$ f(x,y)=[1+(x+y+1)^2(19-14x+3x^2-14y+6xy+3y^2)][30+(2x-3y)^2(18-32x+12x^2+48y-36xy+27y^2)]-3 $$\n",
    "\n",
    "$$ f(0,-1)=0 $$\n",
    "\n",
    "comment: the function value is shifted by a constant $3$ for good plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoldsteinPrice(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [0,-1] 0\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        tmp0 = 1 + (x+y+1)**2 * (19-14*x+3*x*x-14*y+6*x*y+3*y*y)\n",
    "        tmp1 = 30 + (2*x-3*y)**2 * (18-32*x+12*x*x+48*y-36*x*y+27*y*y)\n",
    "        ret = tmp0*tmp1 - 3 #shift 3 for good plotting\n",
    "        return ret\n",
    "\n",
    "model = GoldsteinPrice()\n",
    "x_optim = np.array([0, -1])\n",
    "hf_demo(model, num_repeat=10, xlim=(-2, 2), ylim=(-3, 1), x_optim=x_optim, tag_logscale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Booth function\n",
    "\n",
    "$$ f(x,y)=(x+2y-7)^2 + (2x+y-5)^2 $$\n",
    "\n",
    "$$ f(1,3)=0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Booth(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [1,3] 0\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        tmp0 = x+2*y-7\n",
    "        tmp1 = 2*x+y-5\n",
    "        ret = tmp0*tmp0 + tmp1*tmp1\n",
    "        return ret\n",
    "\n",
    "model = Booth()\n",
    "x_optim = np.array([1, 3])\n",
    "hf_demo(model, num_repeat=10, xlim=(-10, 10), ylim=(-10, 10), x_optim=x_optim, tag_logscale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bukin Function N.6\n",
    "\n",
    "$$ f(x,y)=100\\sqrt{|y-0.01x^2|}+0.01|x+10| $$\n",
    "\n",
    "$$ f(-10,1)=0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BukinFunctionN6(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [-10,1] 0\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        # possible numerical unstable here, also hard for Adam\n",
    "        ret = 100*torch.sqrt(torch.abs(y-0.01*x*x)) + 0.01*torch.abs(x+10)\n",
    "        return ret\n",
    "\n",
    "model = BukinFunctionN6()\n",
    "x_optim = np.array([-10, 1])\n",
    "hf_demo(model, num_repeat=10, xlim=(-15, -5), ylim=(-4, 6), x_optim=x_optim, tag_logscale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matyas function\n",
    "\n",
    "$$ f(x,y)=0.26(x^2+y^2)-0.48xy $$\n",
    "\n",
    "$$ f(0,0)=0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matyas(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [-0,0] 0\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        ret = 0.26*(x*x + y*y) - 0.48*x*y\n",
    "        return ret\n",
    "\n",
    "model = Matyas()\n",
    "x_optim = np.array([0, 0])\n",
    "hf_demo(model, num_repeat=10, xlim=(-10, 10), ylim=(-10, 10), x_optim=x_optim, tag_logscale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levi function N.13\n",
    "\n",
    "$$ f(x,y)=\\sin^2(3\\pi x)+ (x-1)^2(1+\\sin^2(3\\pi y)) + (y-1)^2(1+\\sin^2(2\\pi y)) $$\n",
    "\n",
    "$$ f(1,1)=0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeviFunction(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [0,0] 0\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        ret = torch.sin(3*np.pi*x)**2 + (x-1)**2*(1+torch.sin(3*np.pi*y)**2) + (y-1)**2*(1+torch.sin(2*np.pi*y)**2)\n",
    "        return ret\n",
    "\n",
    "model = LeviFunction()\n",
    "x_optim = np.array([0, 0])\n",
    "hf_demo(model, num_repeat=10, xlim=(-10, 10), ylim=(-10, 10), x_optim=x_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Himmelblau's function\n",
    "\n",
    "$$ f(x,y)=(x^2+y-11)^2 + (x+y^2-7)^2 $$\n",
    "\n",
    "$$ f(3,2)=f(-2.805118,3.131312)=f(-3.779310,-3.283186)=f(3.584428,-1.848126)=0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Himmelblau(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [3,2],[-2.805118,3.131312],[-3.779310,-3.283186],[3.584428,-1.848126] 0\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        tmp0 = x*x + y - 11\n",
    "        tmp1 = x + y*y - 7\n",
    "        ret = tmp0*tmp0 + tmp1*tmp1\n",
    "        return ret\n",
    "\n",
    "model = Himmelblau()\n",
    "x_optim = np.array([[3, 2],[-2.805118,3.131312],[-3.779310,-3.283186],[3.584428,-1.848126]])\n",
    "hf_demo(model, num_repeat=10, xlim=(-5, 5), ylim=(-5, 5), x_optim=x_optim[0], tag_logscale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three-hump camel function\n",
    "\n",
    "$$ f(x,y)=2x^2-1.05x^4+\\frac{x^6}{6}+xy+y^2 $$\n",
    "\n",
    "$$ f(0,0)=0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeHumpCamel(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [0,0] 0\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        ret = 2*x*x - 1.05*x*x*x*x + x*x*x*x*x*x/6 + x*y + y*y\n",
    "        return ret\n",
    "\n",
    "model = ThreeHumpCamel()\n",
    "x_optim = np.array([0, 0])\n",
    "hf_demo(model, num_repeat=10, xlim=(-5, 5), ylim=(-5, 5), x_optim=x_optim, tag_logscale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easom function\n",
    "\n",
    "$$ f(x,y)=-\\cos(x)\\cos(y)\\exp[-(x-\\pi)^2-(y-\\pi)^2] $$\n",
    "\n",
    "$$ f(\\pi,\\pi)=-1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Easom(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [pi,pi] -1\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        ret = -torch.cos(x)*torch.cos(y)*torch.exp(-(x-np.pi)**2-(y-np.pi)**2)\n",
    "        return ret\n",
    "\n",
    "model = Easom()\n",
    "x_optim = np.array([np.pi, np.pi])\n",
    "hf_demo(model, num_repeat=10, xlim=(-100, 100), ylim=(-100, 100), x_optim=x_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-in-tray function\n",
    "\n",
    "$$ f(x,y)=-0.0001\\left[\\left|\\sin(x)\\sin(y)\\exp\\left(\\left|100-\\frac{\\sqrt{x^2+y^2}}{\\pi}\\right|\\right)\\right|+1\\right]^{0.1} $$\n",
    "\n",
    "$$ f(1.34941,-1.34941)=f(1.34941,1.34941)=f(-1.34941,1.34941)=f(-1.34941,-1.34941)=-2.06261 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossInTray(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [1.34941,-1.34941],[1.34941,1.34941],[-1.34941,1.34941],[-1.34941,-1.34941] -2.06261\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        tmp0 = torch.abs(100 - torch.sqrt(x*x + y*y)/np.pi)\n",
    "        tmp1 = torch.abs(torch.sin(x)*torch.sin(y)*torch.exp(tmp0))\n",
    "        ret = -0.0001*tmp1**0.1\n",
    "        return ret\n",
    "\n",
    "model = CrossInTray()\n",
    "x_optim = np.array([[1.34941,-1.34941],[1.34941,1.34941],[-1.34941,1.34941],[-1.34941,-1.34941]])\n",
    "hf_demo(model, num_repeat=10, xlim=(-10, 10), ylim=(-10, 10), x_optim=x_optim[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eggholder function\n",
    "\n",
    "$$ f(x,y)=-(y+47)\\sin\\sqrt{|x/2+(y+47)|}-x\\sin\\sqrt{|x-(y+47)|} $$\n",
    "\n",
    "$$ f(512,404.2319)=-959.6407 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eggholder(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [512,404.2319] -959.6407\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        tmp0 = -(y+47)*torch.sin(torch.sqrt(torch.abs(x/2 + (y+47))))\n",
    "        tmp1 = -x*torch.sin(torch.sqrt(torch.abs(x-(y+47))))\n",
    "        ret = tmp0 + tmp1\n",
    "        return ret\n",
    "\n",
    "model = Eggholder()\n",
    "x_optim = np.array([512, 404.2319])\n",
    "hf_demo(model, num_repeat=10, xlim=(-1000, 1000), ylim=(-1000, 1000), x_optim=x_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holder table function\n",
    "\n",
    "$$ f(x,y)=-\\left|\\sin(x)\\cos(y)\\exp\\left(\\left|1-\\frac{\\sqrt{x^2+y^2}}{\\pi}\\right|\\right)\\right| $$\n",
    "\n",
    "$$ f(8.05502,9.66459)=f(-8.05502, 9.66459)=f(8.05502, -9.66459)=f(-8.05502, -9.66459)=-19.2085 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HolderTable(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [8.05502,9.66459] -19.2085\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        tmp0 = torch.sin(x)*torch.cos(y)\n",
    "        tmp1 = torch.exp(torch.abs(1 - torch.sqrt(x*x + y*y)/np.pi))\n",
    "        ret = -torch.abs(tmp0*tmp1)\n",
    "        return ret\n",
    "\n",
    "model = HolderTable()\n",
    "x_optim = np.array([[8.05502, 9.66459], [-8.05502, 9.66459], [8.05502, -9.66459], [-8.05502, -9.66459]])\n",
    "hf_demo(model, num_repeat=10, xlim=(-10, 10), ylim=(-10, 10), x_optim=x_optim[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McCormick function\n",
    "\n",
    "$$ f(x,y)=\\sin(x+y)+(x-y)^2-1.5x+2.5y+1 $$\n",
    "\n",
    "$$ f(-0.54719,-1.54719)=-1.9133 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class McCormick(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [-0.54719,-1.54719] -1.9133\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        tmp0 = torch.sin(x+y)\n",
    "        tmp1 = (x-y)**2\n",
    "        tmp2 = -1.5*x + 2.5*y + 1\n",
    "        ret = tmp0 + tmp1 + tmp2\n",
    "        return ret\n",
    "\n",
    "# out of domain\n",
    "model = McCormick()\n",
    "x_optim = np.array([-0.54719,-1.54719])\n",
    "hf_demo(model, num_repeat=10, xlim=(-2.5, 4), ylim=(-3, 4), x_optim=x_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schaffer function N.2\n",
    "\n",
    "$$ f(x,y)=0.5+\\frac{\\sin^2(x^2-y^2)-0.5}{[1+0.001(x^2+y^2)]^2} $$\n",
    "\n",
    "$$ f(0,0)=0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchafferFunctionN2(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [0,0] 0\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        tmp0 = torch.sin(x*x-y*y)\n",
    "        tmp1 = 1 + 0.001*(x*x + y*y)\n",
    "        ret = 0.5 + (tmp0*tmp0 - 0.5)/(tmp1*tmp1)\n",
    "        return ret\n",
    "\n",
    "model = SchafferFunctionN2()\n",
    "x_optim = np.array([0, 0])\n",
    "hf_demo(model, num_repeat=10, xlim=(-50, 50), ylim=(-50, 50), x_optim=x_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schaffer function N.4\n",
    "\n",
    "$$ f(x,y)=0.5+\\frac{\\cos^2(\\sin|x^2-y^2|)-0.5}{[1+0.001(x^2+y^2)]^2} $$\n",
    "\n",
    "$$ f(0,1.25313)=f(0,-1.25313)=f(1.25313,0)=f(-1.25313,0)=0.292579 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchafferFunctionN4(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(2)\n",
    "        # [0,1.25313] 0.292579\n",
    "\n",
    "    def forward(self):\n",
    "        x,y = self.theta\n",
    "        tmp0 = torch.cos(torch.sin(torch.abs(x*x-y*y)))\n",
    "        tmp1 = 1 + 0.001*(x*x + y*y)\n",
    "        ret = 0.5 + (tmp0*tmp0 - 0.5)/(tmp1*tmp1)\n",
    "        return ret\n",
    "\n",
    "model = SchafferFunctionN4()\n",
    "x_optim = np.array([[0, 1.25313], [0, -1.25313], [1.25313,0], [-1.25313,0]])\n",
    "hf_demo(model, num_repeat=10, xlim=(-50, 50), ylim=(-50, 50), x_optim=x_optim[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Styblinski-Tang function\n",
    "\n",
    "$$ f(x)=\\frac{1}{2}\\sum_{i=1}^n[x_i^4-16x_i^2+5x_i] $$\n",
    "\n",
    "$$ f(-2.903534,-2.903534,\\cdots,-2.903534)=-39.16599n $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyblinskiTangFunction(torch.nn.Module):\n",
    "    def __init__(self, n) -> None:\n",
    "        super().__init__()\n",
    "        self.theta = hf_uniform_para(n)\n",
    "        # [-2.903534]*n -39.16599*n\n",
    "\n",
    "    def forward(self):\n",
    "        x = self.theta\n",
    "        ret = 0.5*(x*x*x*x - 16*x*x + 5*x).sum()\n",
    "        return ret\n",
    "\n",
    "n = 2\n",
    "model = StyblinskiTangFunction(n)\n",
    "x_optim = np.array([-2.903534]*n)\n",
    "hf_demo(model, num_repeat=10, xlim=(-5, 5), ylim=(-5, 5), x_optim=x_optim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
