{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-Sphere manifold\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/numqi/numqi/blob/main/docs/foundation/manifold/basic_sphere.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import numqi\n",
    "except ImportError:\n",
    "    %pip install numqi\n",
    "    import numqi\n",
    "\n",
    "np_rng = np.random.default_rng()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyMinEigen(torch.nn.Module):\n",
    "    def __init__(self, mat):\n",
    "        super().__init__()\n",
    "        self.mat = torch.tensor(mat, dtype=torch.float64)\n",
    "        self.theta = torch.nn.Parameter(torch.randn(mat.shape[0], dtype=torch.float64))\n",
    "        # self.manifold = numqi.manifold.Sphere(mat.shape[0], dtype=torch.float64)\n",
    "        self.vec = None\n",
    "\n",
    "    def forward(self):\n",
    "        vec = self.theta / torch.linalg.norm(self.theta)\n",
    "        # vec = self.manifold()\n",
    "        self.vec = vec.detach()\n",
    "        loss = torch.vdot(vec, (self.mat @ vec)).real\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N0 = 128\n",
    "tmp0 = np_rng.normal(size=(N0,N0))\n",
    "mat = (tmp0 + tmp0.T) / 2\n",
    "\n",
    "model = DummyMinEigen(mat)\n",
    "callback = numqi.optimize.MinimizeCallback(print_freq=1, extra_key='grad_norm', tag_print=False)\n",
    "theta_optim = numqi.optimize.minimize(model, theta0='uniform', num_repeat=1, callback=callback, tol=1e-14)\n",
    "EVL = theta_optim.fun\n",
    "EVC = model.vec.numpy()\n",
    "EVL_ = np.linalg.eigvalsh(mat)[0]\n",
    "print('error(EVL)', np.abs(EVL-EVL_))\n",
    "print('mae(EVC)', np.abs(mat @ EVC - EVC * EVL).max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax0,ax1) = plt.subplots(1, 2, figsize=(8,4.5))\n",
    "ax0.plot(np.array(callback.state['fval'])-EVL_)\n",
    "ax0.grid()\n",
    "ax0.set_yscale('log')\n",
    "ax0.set_xlabel('step')\n",
    "ax0.set_ylabel('loss-optimal')\n",
    "ax1.plot(callback.state['grad_norm'])\n",
    "ax1.set_yscale('log')\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('step')\n",
    "ax1.set_ylabel('gradient norm')\n",
    "fig.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
