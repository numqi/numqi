{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Started\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/numqi/numqi/blob/main/docs/foundation/get_started/get_started.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "This `get-started` is for new users from optimization perspective. For users with quantum information background, you may start with `Application/get-started`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import numqi\n",
    "except ImportError:\n",
    "    %pip install numqi\n",
    "    import numqi\n",
    "\n",
    "import numqi\n",
    "\n",
    "np_rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconstrained optimization\n",
    "\n",
    "A general unconstrained optimization problem can be formulated as\n",
    "\n",
    "$$ \\min_{x\\in\\mathbb{R}^n} f(x) $$\n",
    "\n",
    "where $f(x)$ is the objective function, $x$ is the optimization variable, and $\\mathbb{R}^n$ is n-dimension Euclidean space, also known as the search space.\n",
    "\n",
    "A specific example is the Rosenbrock function [wiki-link](https://en.wikipedia.org/wiki/Rosenbrock_function)\n",
    "\n",
    "$$ f(x)=\\sum_{i=1}^{n-1}[100(x_{i+1}-x_i^2)^2 + (1-x_i)^2] $$\n",
    "\n",
    "whose global minimum is at $x=(1,1,\\cdots,1)$ and $f(x)=0$.\n",
    "\n",
    "$$ f(1,\\cdots,1)=0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rosenbrock(torch.nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.theta = torch.nn.Parameter(torch.tensor(np_rng.uniform(-1, 1, size=n), dtype=torch.float64))\n",
    "\n",
    "    def forward(self):\n",
    "        tmp0 = self.theta[1:] - self.theta[:-1]**2\n",
    "        tmp1 = 1-self.theta[:-1]\n",
    "        ret = 100*torch.dot(tmp0, tmp0) + torch.dot(tmp1,tmp1)\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first verify that $(1,\\cdots,1)$ gives global minimum of the Rosenbrock function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "model = Rosenbrock(n)\n",
    "hf0 = numqi.optimize.hf_model_wrapper(model)\n",
    "x_optim = np.ones(n)\n",
    "print('f(1,...,1)=', hf0(x_optim, tag_grad=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's try to find the optimal point from random initial points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_optim = numqi.optimize.minimize(model, theta0='uniform', num_repeat=3, tol=1e-10)\n",
    "print('optimal x:', theta_optim.x)\n",
    "print('optimal value:', theta_optim.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, `num_repeat=3` will run the optimization 3 times with different initial points, in hope of finding the global minimum. Under the hood, we call `scipy.optimize.minimize` using `method='L-BFGS-B'`, and the gradient is obtained from pytorch's backward pass.\n",
    "\n",
    "To make it clear, we are NOT saying `numqi` have solved the problem completely (there is no guarantee that the global minimum is found). Even worse, when the dimension is large, the global minimum is hard to find and the convergence might be bad as shown below. `numqi` provides a simple interface for users to start with, and we encourage users to explore more advanced optimization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Rosenbrock(10)\n",
    "theta_optim = numqi.optimize.minimize(model, theta0='uniform', num_repeat=3, tol=1e-10)\n",
    "print('optimal x:', theta_optim.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifold optimization\n",
    "\n",
    "`numqi` is designed to address manifold optimization, one kind of constrained optimization, which can be formulated as\n",
    "\n",
    "$$ \\min_{x\\in\\mathcal{M}} f(x) $$\n",
    "\n",
    "where $\\mathcal{M}$ is a manifold, a subset of $\\mathbb{R}^n$ with some constraints. For example, the n-Sphere manifold $S^n$ is the set of points in $\\mathbb{R}^{n+1}$ that are at a fixed distance from the origin,\n",
    "\n",
    "$$ S^n = \\{x\\in\\mathbb{R}^{n+1} : \\|x\\|_2=1\\} $$\n",
    "\n",
    "PS: Mathemtically, topology is reqiured to clearly define a manifold, which is far beyond the scope of this document (also the author's knowledge).\n",
    "\n",
    "`numqi` adopts the trivialization strategy from [arxiv-link](https://arxiv.org/abs/1909.09501), converting manifold optimization to unconstrained optimization:\n",
    "\n",
    "$$ \\min_{x\\in\\mathbb{R}^n} f(\\phi(x)) $$\n",
    "\n",
    "where $\\phi(x)$ is a mapping from $\\mathbb{R}^n$ to $\\mathcal{M}$.\n",
    "\n",
    "PS: we strongly recommend these two papers for mathematical details about trivialization strategy. `numqi` borrows the idea from them and apply it to quantum information problems.\n",
    "\n",
    "1. [arxiv-link](https://arxiv.org/abs/1909.09501) Trivializations for Gradient-Based Optimization on Manifolds\n",
    "2. [arxiv-link](https://arxiv.org/abs/2203.04794) Geometric Optimisation on Manifolds with Applications to Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mushroom function\n",
    "\n",
    "PS: Mushroom is one of the famous HKUST's sea view landmark, see [hkust-link](https://hkust.edu.hk/multimedia/gallery/atrium), that's why we name this function as Mushroom.\n",
    "\n",
    "$$ \\min_{(x,y)\\in S^1} f(x,y)=x^4+y^4+2x^2y^3 $$\n",
    "\n",
    "It's some polynomial function defined on the 1-Sphere manifold $S^1$. The numerical optimal solution is around\n",
    "\n",
    "$$x^*=\\pm 0.67226298, y^*=-0.74031242, f(x^*,y^*)=0.1378840$$\n",
    "\n",
    "First, we can visualize the function on the 2D plane. (please skip reading the following looooong code block which just for a better visualization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_tableau = ['#4c72b0', '#dd8452', '#55a868', '#c44e52', '#8172b3', '#937860', '#da8bc3', '#8c8c8c', '#ccb974', '#64b5cd']\n",
    "theta_list = np.linspace(0, 2*np.pi, 100)\n",
    "xdata = np.cos(theta_list)\n",
    "ydata = np.sin(theta_list)\n",
    "hf0 = lambda x,y: x**4 + y**4 + 2*x**2*y**3 + 1 #add constant 1 for visualization\n",
    "theta_optim = -2.308057679636519 #from optimization later\n",
    "\n",
    "text_kw = dict(verticalalignment='center', horizontalalignment='center', fontsize=16)\n",
    "arrow_kw = dict(arrowstyle=\"Simple, tail_width=0.5, head_width=4, head_length=8\", color='k')\n",
    "fig,ax = plt.subplots(figsize=(6,5.2))\n",
    "ax.plot(xdata, ydata, color=cp_tableau[0])\n",
    "ax.text(0.3, 1.15, '$(x,y)$', **text_kw, color=cp_tableau[0])\n",
    "ax.text(-0.5, 0, 'circle $S^1$', **text_kw, color=cp_tableau[0])\n",
    "y0 = hf0(0, 1)\n",
    "ax.text(0.35, y0+0.15, '$f(x,y)$', **text_kw, color=cp_tableau[1])\n",
    "ax.plot([0], [1], '.', color=cp_tableau[0], markersize=6)\n",
    "ax.plot([0], [y0], '.', color=cp_tableau[1], markersize=6)\n",
    "ax.add_patch(matplotlib.patches.FancyArrowPatch((0,1.05), (0, y0-0.05), **arrow_kw))\n",
    "fval = hf0(xdata, ydata)\n",
    "ax.plot(xdata*fval, ydata*fval, color=cp_tableau[1])\n",
    "r0 = hf0(np.cos(theta_optim), np.sin(theta_optim))\n",
    "x0 = r0*np.cos(theta_optim)\n",
    "y0 = r0*np.sin(theta_optim)\n",
    "ax.plot([x0,-x0], [y0,y0], 'o', markersize=6, color='red')\n",
    "tmp0 = dict(text_kw)\n",
    "tmp0['fontsize'] = 16\n",
    "ax.text(-x0+0.4, y0-0.15, 'optimal', **tmp0, color='red')\n",
    "ax.set_ylim(-2.5, 2.5)\n",
    "ax.set_aspect('equal')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, each point on the circle $(x,y)\\in S^1$ is mapped to $f(x,y)$ (orange-colored curve, looks like a mushroom). The optimal solution is highlighted by the red dot. From the plot, we can see that the red dot is indeed the global minimum.\n",
    "\n",
    "Then, let's use `numqi` to find the optimal solution in three steps\n",
    "\n",
    "1. define the manifold in `__init__()`\n",
    "2. implement the objective function in `forward()`\n",
    "3. run the minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mushroom(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # define the manifold\n",
    "        self.manifold = numqi.manifold.Sphere(2, dtype=torch.float64)\n",
    "\n",
    "    def forward(self):\n",
    "        # implement the objective function\n",
    "        x,y = self.manifold()\n",
    "        loss = x**4 + y**4 + 2*x**2*y**3\n",
    "        return loss\n",
    "\n",
    "# run the minimization\n",
    "model = Mushroom()\n",
    "theta_optim = numqi.optimize.minimize(model, theta0='uniform', num_repeat=3, tol=1e-10, print_every_round=0)\n",
    "\n",
    "# print the results\n",
    "x,y = model.manifold().detach().numpy()\n",
    "print(x, y, theta_optim.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, you may find the optimal solution in the first run (if not, try more runs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum eigen vector\n",
    "\n",
    "The minimum eigen vector problem is to find the eigenvector corresponding to the smallest eigenvalue of a given matrix $A$.\n",
    "\n",
    "$$ \\min_{x\\in S^{n-1}} f(x)=x^T A x $$\n",
    "\n",
    "where $S^{n-1}$ is the n-Sphere manifold $S^{n-1}=\\{x\\in\\mathbb{R}^n : \\|x\\|_2=1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyMinEigen(torch.nn.Module):\n",
    "    def __init__(self, mat):\n",
    "        super().__init__()\n",
    "        self.mat = torch.tensor(mat, dtype=torch.float64)\n",
    "        self.manifold = numqi.manifold.Sphere(mat.shape[0], dtype=torch.float64)\n",
    "\n",
    "    def forward(self):\n",
    "        vec = self.manifold()\n",
    "        loss = torch.dot(vec, (self.mat @ vec))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we generate a random symmetric matrix $A$ and find the minimum eigen vector using `numqi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N0 = 128\n",
    "tmp0 = np_rng.normal(size=(N0,N0))\n",
    "mat = (tmp0 + tmp0.T) / 2\n",
    "\n",
    "model = DummyMinEigen(mat)\n",
    "theta_optim = numqi.optimize.minimize(model, theta0='uniform', num_repeat=3, tol=1e-14, print_every_round=0)\n",
    "EVL = theta_optim.fun\n",
    "EVC = model.manifold().detach().numpy()\n",
    "EVL_ = np.linalg.eigvalsh(mat)[0]\n",
    "print('error(EVL)', np.abs(EVL-EVL_))\n",
    "print('mae(EVC)', np.abs(mat @ EVC - EVC * EVL).max())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
